{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import torch\n",
    "import yaml\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torch import multiprocessing\n",
    "\n",
    "from mars_dataset import MARSDataset\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()\n",
    "torch.set_default_tensor_type('torch.cuda.FloatTensor')\n",
    "multiprocessing.set_start_method('spawn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('detector_config.yaml', 'r') as ymlfile:\n",
    "    config = yaml.load(ymlfile, Loader=yaml.Loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_json('../MARS-data-tagger/recordings.json')\n",
    "data.dropna(inplace=True)\n",
    "data['y'] = data['label'].apply(lambda x: 1 if x != 'no_whale' else 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from tutorial: https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val = train_test_split(data, \n",
    "                                  test_size=config['TEST_SIZE'], \n",
    "                                  random_state=config['RANDOM_STATE'],\n",
    "                                  stratify=data['y'],\n",
    "                                  )\n",
    "X_train['y'].value_counts(), X_val['y'].value_counts()\n",
    "\n",
    "trainset = MARSDataset(X_train)\n",
    "trainloader = DataLoader(trainset,\n",
    "                         batch_size=config['N_BATCH'], \n",
    "                         shuffle=True, \n",
    "                         num_workers=2,\n",
    "                         generator=torch.Generator(device='cuda'))\n",
    "\n",
    "testset = MARSDataset(X_val)\n",
    "testloader = DataLoader(testset, \n",
    "                        batch_size=config['N_BATCH'], \n",
    "                        shuffle=True, \n",
    "                        num_workers=2,\n",
    "                        generator=torch.Generator(device='cuda'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        # 1 input image channel, 6 output channels, 5x5 square convolution\n",
    "        # kernel\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=6, kernel_size=(5,5))\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        # an affine operation: y = Wx + b\n",
    "        # self.fc1 = nn.Linear(16 * 5 * 5, 120)  # 5*5 from image dimension\n",
    "        self.fc1 = nn.Linear(206976, 1024)\n",
    "        self.fc2 = nn.Linear(1024, 128)\n",
    "        self.fc3 = nn.Linear(128, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Max pooling over a (2, 2) window\n",
    "        x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2))\n",
    "        # If the size is a square, you can specify with a single number\n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)), 2)\n",
    "        x = torch.flatten(x, 1) # flatten all dimensions except the batch dimension\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "net = Net()\n",
    "net.cuda()\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(config['N_EPOCHS']):\n",
    "    print(f'Epoch: {epoch+1} / {config[\"N_EPOCHS\"]}')\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    for i, (inputs, labels) in enumerate(tqdm(trainloader), 0):\n",
    "        \n",
    "        # move data to GPU\n",
    "        inputs = inputs.unsqueeze(1).to(torch.device('cuda'))        \n",
    "        labels = labels.to(torch.device('cuda'))\n",
    "        \n",
    "        # check that inputs are valid\n",
    "        assert ~torch.isnan(inputs).any(), f'input error (nan): {inputs}'\n",
    "        assert ~torch.isinf(inputs).any(), f'input error (inf): {inputs}'\n",
    "        \n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # generate statistics\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    print(f'Loss: {running_loss / (i+1)}')\n",
    "\n",
    "print('Finished Training')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
