{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
    "import pandas as pd\n",
    "import torch\n",
    "import yaml\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torch import multiprocessing\n",
    "# import torchvision\n",
    "\n",
    "\n",
    "from mars_model import SimpleCNN\n",
    "from mars_dataset import MARSDataset\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()\n",
    "torch.set_default_tensor_type('torch.cuda.FloatTensor')\n",
    "multiprocessing.set_start_method('spawn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('detector_config.yaml', 'r') as ymlfile:\n",
    "    config = yaml.load(ymlfile, Loader=yaml.Loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_json(config['DATASET_JSON'])\n",
    "data.dropna(inplace=True)\n",
    "data['y'] = data['label'].apply(lambda x: 1 if x != 'no_whale' else 0) # baseline\n",
    "# data['y'] = data['label'].apply(lambda x: 1 if x == 'whale+' else 0) # highSNR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from tutorial: https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val = train_test_split(data, \n",
    "                                  test_size=config['TEST_SIZE'], \n",
    "                                  random_state=config['RANDOM_STATE'],\n",
    "                                  stratify=data['y'],\n",
    "                                  )\n",
    "\n",
    "trainset = MARSDataset(X_train)\n",
    "trainloader = DataLoader(trainset,\n",
    "                         batch_size=config['N_BATCH'], \n",
    "                         shuffle=True, \n",
    "                         num_workers=2,\n",
    "                         generator=torch.Generator(device='cuda'))\n",
    "\n",
    "testset = MARSDataset(X_val)\n",
    "testloader = DataLoader(testset, \n",
    "                        batch_size=config['N_BATCH'], \n",
    "                        shuffle=True, \n",
    "                        num_workers=2,\n",
    "                        generator=torch.Generator(device='cuda'))\n",
    "\n",
    "classes = (0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = SimpleCNN()\n",
    "net.cuda()\n",
    "print(net)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(config['N_EPOCHS']):\n",
    "    print(f'Epoch: {epoch+1} / {config[\"N_EPOCHS\"]}')\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    for i, (inputs, labels) in enumerate(tqdm(trainloader), 0):\n",
    "        \n",
    "        # move data to GPU\n",
    "        inputs = inputs.unsqueeze(1).to(torch.device('cuda'))        \n",
    "        labels = labels.to(torch.device('cuda'))\n",
    "        \n",
    "        # check that inputs are valid\n",
    "        assert ~torch.isnan(inputs).any(), f'input error (nan): {inputs}'\n",
    "        assert ~torch.isinf(inputs).any(), f'input error (inf): {inputs}'\n",
    "        \n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # generate statistics\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    print(f'Loss: {running_loss / (i+1)}')\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(net.state_dict(), config['MODEL_PATH'] + config['MODEL_NAME'] + '.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = SimpleCNN()\n",
    "net.load_state_dict(torch.load(config['MODEL_PATH'] + config['MODEL_NAME'] + '.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = []\n",
    "y_pred = []\n",
    "\n",
    "# since we're not training, we don't need to calculate the gradients for our outputs\n",
    "with torch.no_grad():\n",
    "    for i, (inputs, labels) in enumerate(tqdm(testloader)):\n",
    "        inputs = inputs.unsqueeze(1).to(torch.device('cuda'))\n",
    "        labels = labels.to(torch.device('cuda'))\n",
    "        # calculate outputs by running images through the network\n",
    "        outputs = net(inputs)\n",
    "        # the class with the highest energy is what we choose as prediction\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        y_true += labels.cpu().tolist()\n",
    "        y_pred += predicted.cpu().tolist()\n",
    "\n",
    "# print(f'Accuracy of the network on the testset: {(correct / total):.4f}')\n",
    "print(f'Accuracy:  {accuracy_score(y_true, y_pred):.4f}')\n",
    "print(f'Precision: {precision_score(y_true, y_pred):.4f}')\n",
    "print(f'Recall:    {recall_score(y_true, y_pred):.4f}')\n",
    "print(f'F1:        {f1_score(y_true, y_pred):.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "baseline after 16 epochs:\n",
    "\n",
    "|   | score |\n",
    "| :- | -: |\n",
    "| Accuracy |  0.6379 |\n",
    "| Precision | 0.6379 |\n",
    "| Recall | 1.0000 |\n",
    "| F1 | 0.7789 |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "baseline_highSNR after 8 epochs:\n",
    "\n",
    "|   | score |\n",
    "| :- | -: |\n",
    "| Accuracy |  0.8695 |\n",
    "| Precision | 0.0000 |\n",
    "| Recall | 0.0000 |\n",
    "| F1 | 0.0000 |\n",
    "\n",
    "The 0s for precsion, recall, and F1 mean that there are no true positives, i.e. the model predicts everything as \"no whale\"\n",
    "\n",
    "This result is likely due to an unbalanced dataset with few examples of high SNR whales"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
