{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score, confusion_matrix\n",
    "import pandas as pd\n",
    "import torch\n",
    "import yaml\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torch import multiprocessing\n",
    "from torchsummary import summary\n",
    "\n",
    "\n",
    "from mars_model import BinaryClassifier\n",
    "from mars_dataset import MARSDataset\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()\n",
    "torch.set_default_tensor_type('torch.cuda.FloatTensor')\n",
    "multiprocessing.set_start_method('spawn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('detector_config.yaml', 'r') as ymlfile:\n",
    "    config = yaml.load(ymlfile, Loader=yaml.Loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_json(config['DATASET_ROOT'] + config['DATASET_JSON'])\n",
    "data.dropna(inplace=True)\n",
    "# data['y'] = data['label'].apply(lambda x: 1 if x != 'no_whale' else 0) # baseline\n",
    "data['y'] = data['label'].apply(lambda x: 1 if x == 'whale+' else 0) # highSNR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Balancing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_whale = data[data['y'] == 1]['y'].count() # there are many fewer whale samples than no_whale\n",
    "whale = data[data['y'] == 1]\n",
    "nowhale = data[data['y'] == 0].sample(n=num_whale, random_state=1)\n",
    "data = pd.concat([whale, nowhale])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val = train_test_split(data, \n",
    "                                  test_size=config['TEST_SIZE'], \n",
    "                                  random_state=config['RANDOM_STATE'],\n",
    "                                  stratify=data['y'],\n",
    "                                  )\n",
    "\n",
    "trainset = MARSDataset(X_train)\n",
    "testset = MARSDataset(X_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from tutorial: https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainloader = DataLoader(trainset,\n",
    "                         batch_size=config['N_BATCH'], \n",
    "                         shuffle=True, \n",
    "                         num_workers=2,\n",
    "                         generator=torch.Generator(device='cuda'))\n",
    "\n",
    "testloader = DataLoader(testset, \n",
    "                        batch_size=config['N_BATCH'], \n",
    "                        shuffle=True, \n",
    "                        num_workers=2,\n",
    "                        generator=torch.Generator(device='cuda'))\n",
    "\n",
    "classes = (0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = BinaryClassifier().cuda()\n",
    "\n",
    "criterion = nn.BCELoss()\n",
    "# optimizer = optim.SGD(net.parameters(), \n",
    "#                       lr=config['LEARNING_RATE'], \n",
    "#                       momentum=config['MOMENTUM'])\n",
    "optimizer = optim.Adam(net.parameters(),\n",
    "                       lr=config['LEARNING_RATE'])\n",
    "\n",
    "summary(net, (1, 180, 1244))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# net = SimpleCNN()\n",
    "# net.cuda()\n",
    "\n",
    "# criterion = nn.CrossEntropyLoss()\n",
    "# optimizer = optim.SGD(net.parameters(), \n",
    "#                       lr=config['LEARNING_RATE'], \n",
    "#                       momentum=config['MOMENTUM'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# net = ResNet(ResidualBlock, [1, 4, 6, 3], 2).cuda()\n",
    "# criterion = nn.CrossEntropyLoss()\n",
    "# # optimizer = optim.SGD(net.parameters(), \n",
    "# #                       lr=config['LEARNING_RATE'], \n",
    "# #                       momentum=config['MOMENTUM'])\n",
    "\n",
    "# optimizer = optim.Adam(net.parameters(),\n",
    "#                        lr=config['LEARNING_RATE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_loss = 1000.0 # initialize to large value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(config['N_EPOCHS']): # loop through epochs\n",
    "    print(f'Epoch: {epoch+1} / {config[\"N_EPOCHS\"]}')\n",
    "    running_loss = 0.0 # reset\n",
    "    \n",
    "    for i, (inputs, labels, _) in enumerate(tqdm(trainloader), 0): # loop through batches\n",
    "        \n",
    "        # move data to GPU\n",
    "        # inputs = inputs.unsqueeze(1).to(torch.device('cuda'))     \n",
    "        inputs = inputs.cuda()  \n",
    "        labels = labels.cuda().float()\n",
    "        \n",
    "        # check that inputs are valid\n",
    "        assert ~torch.isnan(inputs).any(), f'input error (nan): {inputs}'\n",
    "        assert ~torch.isinf(inputs).any(), f'input error (inf): {inputs}'\n",
    "        \n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs).squeeze()\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # generate statistics\n",
    "        running_loss += loss.item()\n",
    "    epoch_loss = running_loss / (i+1)\n",
    "    print(f'Loss: {epoch_loss:.4f}, min loss: {min_loss}')\n",
    "    if epoch_loss < min_loss:\n",
    "        min_loss = epoch_loss\n",
    "        print('saving...')\n",
    "        torch.save(net.state_dict(), config['MODEL_ROOT'] + config['MODEL_NAME'] + '_b' + '.pth')\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = BinaryClassifier().cuda()\n",
    "# net = ResNet(ResidualBlock, [1, 4, 6, 3], 2).cuda()\n",
    "# net = SimpleCNN().cuda()\n",
    "\n",
    "net.load_state_dict(torch.load(config['MODEL_ROOT'] + config['MODEL_NAME'] + '.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = []\n",
    "y_pred = []\n",
    "\n",
    "# since we're not training, we don't need to calculate the gradients for our outputs\n",
    "with torch.no_grad():\n",
    "    for i, (inputs, labels, _) in enumerate(tqdm(testloader)):\n",
    "        inputs = inputs.cuda()\n",
    "        labels = labels.cuda().float()\n",
    "        # calculate outputs by running images through the network\n",
    "        outputs = net(inputs)\n",
    "        # the class with the highest energy is what we choose as prediction\n",
    "        # _, predicted = torch.max(outputs.data, 1) # for softmax classifier\n",
    "        predicted = outputs.round() # for binary classifier with sigmoid\n",
    "        y_true += labels.cpu().tolist()\n",
    "        y_pred += predicted.cpu().tolist()\n",
    "try:\n",
    "    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
    "except:\n",
    "    pass\n",
    "\n",
    "# print(f'Accuracy of the network on the testset: {(correct / total):.4f}')\n",
    "print(f'Accuracy:  {accuracy_score(y_true, y_pred):.4f}')\n",
    "print(f'Precision: {precision_score(y_true, y_pred):.4f}')\n",
    "print(f'Recall:    {recall_score(y_true, y_pred):.4f}')\n",
    "print(f'F1:        {f1_score(y_true, y_pred):.4f}')\n",
    "print(f'Confusion:\\nTP: {tp}\\nFP: {fp}\\nTN: {tn}\\nFN: {fn}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model using BinaryClassifier on Mel-spectrogram data\n",
    "\n",
    "Accuracy:  0.8696\n",
    "- Precision: 0.8806\n",
    "- Recall:    0.8551\n",
    "- F1:        0.8676\n",
    "- Confusion:\n",
    "    - TP: 59\n",
    "    - FP: 8\n",
    "    - TN: 61\n",
    "    - FN: 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "examine errors and update data labels as needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def change_label(filename, label):\n",
    "#     df = pd.read_json(config['DATASET_ROOT'] + config['DATASET_JSON'])\n",
    "#     df.loc[df['filename']== filename, 'label'] = label\n",
    "#     df.to_json(config['DATASET_ROOT'] + config['DATASET_JSON'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change_label('20230923_100023Z.mp3', 'whale')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change_label('20231002_010052Z.mp3', 'whale')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # since we're not training, we don't need to calculate the gradients for our outputs\n",
    "# with torch.no_grad():\n",
    "#     for i, (inputs, labels, fname) in enumerate(tqdm(testloader)):\n",
    "#         inputs = inputs.unsqueeze(1).to(torch.device('cuda'))\n",
    "#         labels = labels.to(torch.device('cuda'))\n",
    "#         # calculate outputs by running images through the network\n",
    "#         outputs = net(inputs)\n",
    "#         # the class with the highest energy is what we choose as prediction\n",
    "#         _, predicted = torch.max(outputs.data, 1)\n",
    "#         y_true = labels.cpu().tolist()\n",
    "#         y_pred = predicted.cpu().tolist()\n",
    "#         if (y_true==[1]) and (y_pred==[0]):\n",
    "#             print(f'{fname}\\npredicted: {y_pred}\\nground truth: {y_true}')\n",
    "#             plt.imshow(np.flipud(inputs.cpu().numpy().squeeze()), cmap='jet')\n",
    "#             plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from mars_clip import MarsClip\n",
    "# clip = MarsClip('20231005_040052Z.mp3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sxx, _, _ = clip.get_spec_img()\n",
    "# plt.imshow(np.flipud(sxx), cmap='jet')\n",
    "# plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
